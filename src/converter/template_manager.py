# src/converter/template_manager.py
import os
import jinja2
from pathlib import Path
from typing import Dict, Any, Optional
import yaml

class TemplateManager:
    def __init__(self, template_dir: str = "templates"):
        self.template_dir = Path(template_dir)
        self._ensure_template_dir()
        self._load_templates()
    
    def _ensure_template_dir(self):
        """Ensure template directory exists with default templates"""
        self.template_dir.mkdir(exist_ok=True)
        
        # Create default templates if they don't exist
        default_templates = {
            "main_script.j2": self._get_main_script_template(),
            "functions_module.j2": self._get_functions_template(),
            "training_module.j2": self._get_training_template(),
            "config_py.j2": self._get_config_template(),
            "requirements.j2": self._get_requirements_template(),
            "dockerfile.j2": self._get_dockerfile_template()
        }
        
        for template_name, template_content in default_templates.items():
            template_path = self.template_dir / template_name
            if not template_path.exists():
                template_path.write_text(template_content)
        
        self.env = jinja2.Environment(
            loader=jinja2.FileSystemLoader(self.template_dir),
            trim_blocks=True,
            lstrip_blocks=True
        )
    
    def _load_templates(self):
        """Load all available templates"""
        self.templates = {}
        for template_file in self.template_dir.glob("*.j2"):
            template_name = template_file.stem
            self.templates[template_name] = self.env.get_template(template_file.name)
    
    def render_template(self, template_name: str, context: Dict[str, Any]) -> str:
        """Render a template with given context"""
        if template_name not in self.templates:
            raise ValueError(f"Template '{template_name}' not found")
        
        return self.templates[template_name].render(**context)
    
    def create_custom_template(self, template_name: str, content: str):
        """Create a new custom template"""
        template_path = self.template_dir / f"{template_name}.j2"
        template_path.write_text(content)
        self._load_templates()  # Reload templates
    
    def get_available_templates(self) -> list:
        """Get list of available templates"""
        return list(self.templates.keys())
    
    # Default template content methods
    def _get_main_script_template(self) -> str:
        return """#!/usr/bin/env python3
\"\"\"
Main execution script generated from Jupyter notebook
Generated by ML DevOps Converter
\"\"\"

{% if imports %}
# Import section
{% for import_block in imports %}
{{ import_block }}
{% endfor %}
{% endif %}

{% if config_import %}
# Configuration
{{ config_import }}
{% endif %}

def main():
    \"\"\"Main execution function\"\"\"
    {% for category, cells in execution_cells.items() %}
    # {{ category.replace('_', ' ').title() }}
    {% for cell in cells %}
    {{ cell.source }}
    {% endfor %}
    {% endfor %}

if __name__ == "__main__":
    main()
"""
    
    def _get_functions_template(self) -> str:
        return """\"\"\"
Utility functions generated from Jupyter notebook
\"\"\"

{% for cell in function_cells %}
{{ cell.source }}
{% endfor %}

# Generated helper functions
def setup_logging():
    \"\"\"Setup logging configuration\"\"\"
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

def save_model(model, filepath):
    \"\"\"Save model with proper serialization\"\"\"
    import pickle
    import joblib
    try:
        # Try joblib first (better for scikit-learn)
        joblib.dump(model, filepath)
    except:
        # Fallback to pickle
        with open(filepath, 'wb') as f:
            pickle.dump(model, f)
"""
    
    def _get_training_template(self) -> str:
        return """\"\"\"
Training module for machine learning models
\"\"\"

import logging
from pathlib import Path

logger = logging.getLogger(__name__)

{% for cell in training_cells %}
{{ cell.source }}
{% endfor %}

class ModelTrainer:
    \"\"\"Unified model training class\"\"\"
    
    def __init__(self, config=None):
        self.config = config or {}
        self.model = None
        self.history = None
    
    def train(self, X_train, y_train, X_val=None, y_val=None):
        \"\"\"Train model with validation\"\"\"
        raise NotImplementedError("Subclasses must implement train method")
    
    def evaluate(self, X_test, y_test):
        \"\"\"Evaluate model performance\"\"\"
        raise NotImplementedError("Subclasses must implement evaluate method")
    
    def save(self, filepath):
        \"\"\"Save trained model\"\"\"
        import joblib
        joblib.dump(self.model, filepath)
        logger.info(f"Model saved to {filepath}")
"""
    
    def _get_config_template(self) -> str:
        return """\"\"\"
Configuration file for ML project
Generated automatically from notebook analysis
\"\"\"

import os
from pathlib import Path

# Project paths
PROJECT_ROOT = Path(__file__).parent.parent
DATA_DIR = PROJECT_ROOT / 'data'
MODELS_DIR = PROJECT_ROOT / 'models'
REPORTS_DIR = PROJECT_ROOT / 'reports'
SRC_DIR = PROJECT_ROOT / 'src'

# Data configuration
class DataConfig:
    RAW_DATA_PATH = DATA_DIR / 'raw'
    PROCESSED_DATA_PATH = DATA_DIR / 'processed'
    EXTERNAL_DATA_PATH = DATA_DIR / 'external'
    
    # Data file patterns
    CSV_PATTERNS = ['*.csv', '*.tsv']
    IMAGE_PATTERNS = ['*.jpg', '*.png', '*.jpeg']
    
    @classmethod
    def create_dirs(cls):
        \"\"\"Create data directories if they don't exist\"\"\"
        cls.RAW_DATA_PATH.mkdir(parents=True, exist_ok=True)
        cls.PROCESSED_DATA_PATH.mkdir(parents=True, exist_ok=True)
        cls.EXTERNAL_DATA_PATH.mkdir(parents=True, exist_ok=True)

# Model configuration
class ModelConfig:
    SAVE_PATH = MODELS_DIR / 'trained'
    CHECKPOINT_PATH = MODELS_DIR / 'checkpoints'
    
    # Training parameters
    DEFAULT_HYPERPARAMETERS = {
        'random_state': 42,
        'test_size': 0.2,
        'validation_size': 0.1,
        'batch_size': 32,
        'epochs': 10
    }
    
    @classmethod
    def create_dirs(cls):
        \"\"\"Create model directories if they don't exist\"\"\"
        cls.SAVE_PATH.mkdir(parents=True, exist_ok=True)
        cls.CHECKPOINT_PATH.mkdir(parents=True, exist_ok=True)

# Experiment tracking
class ExperimentConfig:
    TRACKING_URI = PROJECT_ROOT / 'mlruns'
    EXPERIMENT_NAME = 'default_experiment'
    
    # Supported trackers
    USE_MLFLOW = False
    USE_WANDB = False

# Initialize directories on import
DataConfig.create_dirs()
ModelConfig.create_dirs()
"""
    
    def _get_requirements_template(self) -> str:
        return """# Generated requirements file
# Core dependencies
{% for lib in core_dependencies %}
{{ lib }}
{% endfor %}

# Data science ecosystem
{% for lib in data_science_dependencies %}
{{ lib }}
{% endfor %}

# Machine Learning frameworks
{% for lib in ml_framework_dependencies %}
{{ lib }}
{% endfor %}

# Visualization libraries
{% for lib in visualization_dependencies %}
{{ lib }}
{% endfor %}

# Utilities
jupyter>=1.0.0
ipykernel>=6.0.0
"""
    
    def _get_dockerfile_template(self) -> str:
        return """# ML Project Dockerfile
FROM python:3.9-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    g++ \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy project files
COPY . .

# Create necessary directories
RUN mkdir -p data/raw data/processed models/trained reports/figures

{% if entrypoint %}
CMD {{ entrypoint }}
{% else %}
CMD ["python", "src/main.py"]
{% endif %}
"""