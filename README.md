# MLOps_converter# ML DevOps Converter

A powerful tool that transforms Jupyter notebooks into production-ready Python projects with comprehensive DevOps features. Streamline your machine learning workflow from experimentation to deployment.

## ðŸš€ Features

### ðŸ”„ Notebook Conversion
- **Smart Code Organization**: Automatically categorizes notebook cells into logical Python modules
- **Dependency Analysis**: Detects and analyzes imported packages
- **Code Quality**: Generates clean, well-structured Python code
- **Template System**: Customizable code generation templates

### ðŸ—ï¸ Project Management
- **Standard ML Project Structure**: Creates organized directory layouts
- **Configuration Management**: Generates framework-specific configuration files
- **Multiple Framework Support**: TensorFlow, PyTorch, Scikit-learn, and generic ML projects

### ðŸ”§ DevOps Integration
- **Version Control**: Automatic Git initialization with ML-optimized hooks
- **Data Versioning**: DVC setup for large datasets and models
- **CI/CD Templates**: GitHub Actions workflows for ML pipelines
- **Branch Management**: Standard branch structure for ML projects

### ðŸ“Š Project Health
- **Status Monitoring**: Check project health and configuration
- **Dependency Tracking**: Automated requirements.txt generation
- *# ML DevOps Converter

A powerful tool that transforms Jupyter notebooks into production-ready Python projects with comprehensive DevOps features. Streamline your machine learning workflow from experimentation to deployment.

## ðŸš€ Features

### ðŸ”„ Notebook Conversion
- **Smart Code Organization**: Automatically categorizes notebook cells into logical Python modules
- **Dependency Analysis**: Detects and analyzes imported packages
- **Code Quality**: Generates clean, well-structured Python code
- **Template System**: Customizable code generation templates

### ðŸ—ï¸ Project Management
- **Standard ML Project Structure**: Creates organized directory layouts
- **Configuration Management**: Generates framework-specific configuration files
- **Multiple Framework Support**: TensorFlow, PyTorch, Scikit-learn, and generic ML projects

### ðŸ”§ DevOps Integration
- **Version Control**: Automatic Git initialization with ML-optimized hooks
- **Data Versioning**: DVC setup for large datasets and models
- **CI/CD Templates**: GitHub Actions workflows for ML pipelines
- **Branch Management**: Standard branch structure for ML projects

### ðŸ“Š Project Health
- **Status Monitoring**: Check project health and configuration
- **Dependency Tracking**: Automated requirements.txt generation
- **Structure Validation**: Ensure project follows ML best practices

## ðŸ“¦ Installation

### From Source
```bash
git clone https://github.com/yourusername/ml_devops_converter
cd ml_devops_converter
pip install -e .
```

### Requirements
- Python 3.7+
- Dependencies: `click`, `nbformat`, `pyyaml`, `jinja2`

## ðŸ› ï¸ Quick Start

### Convert a Notebook to Production Code
```bash
# Basic conversion
ml-converter convert my_notebook.ipynb --output-dir ./my_project

# Full DevOps setup
ml-converter convert my_notebook.ipynb \
    --output-dir ./production_ready \
    --create-structure \
    --analyze-deps \
    --framework pytorch \
    --setup-vcs \
    --setup-dvc \
    --setup-ci \
    --generate-config
```

### Initialize a New ML Project
```bash
ml-converter init my_ml_project \
    --framework tensorflow \
    --with-vcs \
    --with-ci
```

## ðŸ“š Usage Examples

### Basic Conversion
```bash
ml-converter convert experiment.ipynb --output-dir ./converted
```

### With Project Structure
```bash
ml-converter convert experiment.ipynb \
    --create-structure \
    --analyze-deps \
    --output-dir ./organized_project
```

### Full ML DevOps Pipeline
```bash
ml-converter convert research.ipynb \
    --output-dir ./production_model \
    --create-structure \
    --analyze-deps \
    --framework tensorflow \
    --setup-vcs \
    --setup-dvc \
    --dvc-remote s3://my-bucket/models \
    --setup-ci \
    --generate-config
```

### Project Management Commands
```bash
# Check project health
ml-converter status ./my_project

# Setup version control for existing project
ml-converter setup-vcs ./my_project --with-dvc --with-ci

# Generate configuration files
ml-converter setup-config ./my_project --framework pytorch

# List available templates
ml-converter list-templates

# Create custom template
ml-converter create-template my_template --content "Custom code template"
```

## ðŸ—ï¸ Generated Project Structure

```
project_name/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/          # Raw datasets
â”‚   â”œâ”€â”€ processed/    # Processed data
â”‚   â””â”€â”€ external/     # External data sources
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ trained/      # Trained models
â”‚   â””â”€â”€ pretrained/   # Pre-trained models
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py       # Main execution script
â”‚   â”œâ”€â”€ functions.py  # Utility functions
â”‚   â”œâ”€â”€ training.py   # Model training code
â”‚   â”œâ”€â”€ config.py     # Python configuration
â”‚   â””â”€â”€ dependencies_analysis.json
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploratory/  # Exploration notebooks
â”‚   â””â”€â”€ experimental/ # Experiment notebooks
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/         # Unit tests
â”‚   â””â”€â”€ integration/  # Integration tests
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ project_config.yaml
â”‚   â”œâ”€â”€ environment.yaml
â”‚   â””â”€â”€ training_config.yaml
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/      # Output figures and plots
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ml-pipeline.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## âš™ï¸ Configuration

### Framework Support
- **TensorFlow**: Optimized for Keras and TF workflows
- **PyTorch**: Custom configurations for PyTorch projects
- **Scikit-learn**: Traditional ML pipeline setup
- **Generic**: Framework-agnostic ML project structure

### Generated Configuration Files

1. **project_config.yaml**: Project metadata and paths
2. **environment.yaml**: Conda environment specification
3. **training_config.yaml**: Training parameters and hyperparameters
4. **data_config.yaml**: Data preprocessing and validation settings

## ðŸ”„ Version Control Features

### Git Integration
- Automatic repository initialization
- ML-optimized .gitignore
- Pre-commit hooks for code quality
- Post-commit hooks for experiment tracking

### DVC Setup
- Data and model versioning
- Remote storage configuration (S3, GCS, Azure, local)
- Pipeline management

### CI/CD Templates
- Automated testing
- Model training pipelines
- Code quality checks
- Coverage reporting

## ðŸŽ¯ Cell Categorization

The converter intelligently categorizes notebook cells:

| Category | Description | Output File |
|----------|-------------|-------------|
| `imports` | Package imports | `main.py` |
| `function_definitions` | Functions and classes | `functions.py` |
| `model_training` | Training loops and model code | `training.py` |
| `data_processing` | Data cleaning and preprocessing | `main.py` |
| `visualization` | Plots and charts | `main.py` |
| `general_code` | Miscellaneous code | `main.py` |

## ðŸ“Š Dependency Analysis

Automatically detects and categorizes Python packages:

- **Core Dependencies**: Essential Python packages
- **Data Science**: NumPy, Pandas, Scikit-learn
- **ML Frameworks**: TensorFlow, PyTorch, XGBoost
- **Visualization**: Matplotlib, Seaborn, Plotly

## ðŸ› ï¸ Advanced Usage

### Custom Templates
Create custom code generation templates:

```bash
ml-converter create-template custom_module --file ./my_template.j2
```

### Project Health Check
```bash
ml-converter status ./my_project
```
Output includes:
- Project structure validation
- Version control status
- Configuration file checks
- Dependency analysis

### Branch Management
```bash
ml-converter setup-vcs ./my_project --create-branches
```
Creates standard branches:
- `main` - Production code
- `develop` - Development branch
- `experiment/*` - Experimental features

## ðŸ”§ Troubleshooting

### Common Issues

1. **Notebook parsing errors**
   ```bash
   # Check notebook validity
   python -m json.tool notebook.ipynb > /dev/null
   ```

2. **Missing dependencies**
   ```bash
   pip install nbformat pyyaml jinja2 click
   ```

3. **Permission errors**
   ```bash
   chmod +x src/cli/main.py
   ```

### Debug Mode
```bash
# Enable debug output
ml-converter convert notebook.ipynb --output-dir ./debug_output -v
```

## ðŸ“ˆ Example Workflow

### From Research to Production
1. **Experiment**: Develop model in Jupyter notebook
2. **Convert**: `ml-converter convert model.ipynb --create-structure --analyze-deps`
3. **Version**: `ml-converter setup-vcs ./model --with-dvc --with-ci`
4. **Configure**: `ml-converter setup-config ./model --framework tensorflow`
5. **Deploy**: Push to repository, CI/CD handles testing and deployment

## ðŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Setup
```bash
git clone https://github.com/yourusername/ml_devops_converter
cd ml_devops_converter
pip install -e ".[dev]"
pre-commit install
```

### Running Tests
```bash
pytest tests/ -v
```

## ï¿½ï¿½ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

- Inspired by ML industry best practices
- Built with the Python data science ecosystem
- Thanks to the open-source community for excellent tools and libraries

---

**ML DevOps Converter** - Bridge the gap between research and production with intelligent notebook conversion and comprehensive DevOps integration.*Structure Validation**: Ensure project follows ML best practices

## ðŸ“¦ Installation

### From Source
```bash
git clone https://github.com/yourusername/ml_devops_converter
cd ml_devops_converter
pip install -e .
```

### Requirements
- Python 3.7+
- Dependencies: `click`, `nbformat`, `pyyaml`, `jinja2`

## ðŸ› ï¸ Quick Start

### Convert a Notebook to Production Code
```bash
# Basic conversion
ml-converter convert my_notebook.ipynb --output-dir ./my_project

# Full DevOps setup
ml-converter convert my_notebook.ipynb \
    --output-dir ./production_ready \
    --create-structure \
    --analyze-deps \
    --framework pytorch \
    --setup-vcs \
    --setup-dvc \
    --setup-ci \
    --generate-config
```

### Initialize a New ML Project
```bash
ml-converter init my_ml_project \
    --framework tensorflow \
    --with-vcs \
    --with-ci
```

## ðŸ“š Usage Examples

### Basic Conversion
```bash
ml-converter convert experiment.ipynb --output-dir ./converted
```

### With Project Structure
```bash
ml-converter convert experiment.ipynb \
    --create-structure \
    --analyze-deps \
    --output-dir ./organized_project
```

### Full ML DevOps Pipeline
```bash
ml-converter convert research.ipynb \
    --output-dir ./production_model \
    --create-structure \
    --analyze-deps \
    --framework tensorflow \
    --setup-vcs \
    --setup-dvc \
    --dvc-remote s3://my-bucket/models \
    --setup-ci \
    --generate-config
```

### Project Management Commands
```bash
# Check project health
ml-converter status ./my_project

# Setup version control for existing project
ml-converter setup-vcs ./my_project --with-dvc --with-ci

# Generate configuration files
ml-converter setup-config ./my_project --framework pytorch

# List available templates
ml-converter list-templates

# Create custom template
ml-converter create-template my_template --content "Custom code template"
```

## ðŸ—ï¸ Generated Project Structure

```
project_name/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/          # Raw datasets
â”‚   â”œâ”€â”€ processed/    # Processed data
â”‚   â””â”€â”€ external/     # External data sources
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ trained/      # Trained models
â”‚   â””â”€â”€ pretrained/   # Pre-trained models
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py       # Main execution script
â”‚   â”œâ”€â”€ functions.py  # Utility functions
â”‚   â”œâ”€â”€ training.py   # Model training code
â”‚   â”œâ”€â”€ config.py     # Python configuration
â”‚   â””â”€â”€ dependencies_analysis.json
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploratory/  # Exploration notebooks
â”‚   â””â”€â”€ experimental/ # Experiment notebooks
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/         # Unit tests
â”‚   â””â”€â”€ integration/  # Integration tests
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ project_config.yaml
â”‚   â”œâ”€â”€ environment.yaml
â”‚   â””â”€â”€ training_config.yaml
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/      # Output figures and plots
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ml-pipeline.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## âš™ï¸ Configuration

### Framework Support
- **TensorFlow**: Optimized for Keras and TF workflows
- **PyTorch**: Custom configurations for PyTorch projects
- **Scikit-learn**: Traditional ML pipeline setup
- **Generic**: Framework-agnostic ML project structure

### Generated Configuration Files

1. **project_config.yaml**: Project metadata and paths
2. **environment.yaml**: Conda environment specification
3. **training_config.yaml**: Training parameters and hyperparameters
4. **data_config.yaml**: Data preprocessing and validation settings

## ðŸ”„ Version Control Features

### Git Integration
- Automatic repository initialization
- ML-optimized .gitignore
- Pre-commit hooks for code quality
- Post-commit hooks for experiment tracking

### DVC Setup
- Data and model versioning
- Remote storage configuration (S3, GCS, Azure, local)
- Pipeline management

### CI/CD Templates
- Automated testing
- Model training pipelines
- Code quality checks
- Coverage reporting

## ðŸŽ¯ Cell Categorization

The converter intelligently categorizes notebook cells:

| Category | Description | Output File |
|----------|-------------|-------------|
| `imports` | Package imports | `main.py` |
| `function_definitions` | Functions and classes | `functions.py` |
| `model_training` | Training loops and model code | `training.py` |
| `data_processing` | Data cleaning and preprocessing | `main.py` |
| `visualization` | Plots and charts | `main.py` |
| `general_code` | Miscellaneous code | `main.py` |

## ðŸ“Š Dependency Analysis

Automatically detects and categorizes Python packages:

- **Core Dependencies**: Essential Python packages
- **Data Science**: NumPy, Pandas, Scikit-learn
- **ML Frameworks**: TensorFlow, PyTorch, XGBoost
- **Visualization**: Matplotlib, Seaborn, Plotly

## ðŸ› ï¸ Advanced Usage

### Custom Templates
Create custom code generation templates:

```bash
ml-converter create-template custom_module --file ./my_template.j2
```

### Project Health Check
```bash
ml-converter status ./my_project
```
Output includes:
- Project structure validation
- Version control status
- Configuration file checks
- Dependency analysis

### Branch Management
```bash
ml-converter setup-vcs ./my_project --create-branches
```
Creates standard branches:
- `main` - Production code
- `develop` - Development branch
- `experiment/*` - Experimental features

## ðŸ”§ Troubleshooting

### Common Issues

1. **Notebook parsing errors**
   ```bash
   # Check notebook validity
   python -m json.tool notebook.ipynb > /dev/null
   ```

2. **Missing dependencies**
   ```bash
   pip install nbformat pyyaml jinja2 click
   ```

3. **Permission errors**
   ```bash
   chmod +x src/cli/main.py
   ```

### Debug Mode
```bash
# Enable debug output
ml-converter convert notebook.ipynb --output-dir ./debug_output -v
```

## ðŸ“ˆ Example Workflow

### From Research to Production
1. **Experiment**: Develop model in Jupyter notebook
2. **Convert**: `ml-converter convert model.ipynb --create-structure --analyze-deps`
3. **Version**: `ml-converter setup-vcs ./model --with-dvc --with-ci`
4. **Configure**: `ml-converter setup-config ./model --framework tensorflow`
5. **Deploy**: Push to repository, CI/CD handles testing and deployment


### Development Setup
```bash
git clone https://github.com/yourusername/ml_devops_converter
cd ml_devops_converter
pip install -e ".[dev]"
pre-commit install
```

### Running Tests
```bash
pytest tests/ -v
```

